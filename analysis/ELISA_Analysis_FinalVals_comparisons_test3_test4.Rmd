---
title: "Comparing calculation methods, test3 and test4"
output: html_document
date: "2025-04-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(knitr)
library(ggplot2)
library(broom)
library(paletteer)
library(dplyr)
library(tidyverse)
library(readr)

```

# Test4

*Plate description*

Category	  Description
---------  ---------------------------------------------------------------
TA        	Non-spiked serial dilution
TB         	Spiked only in first dilution (TB1) then serially diluted
TC        	Each dilution individually spiked with 25 µL of std1
TD          First tube spiked 1:1 with std1 (110 µL), then serially diluted
TP        	Precision replicates (different weights: 6, 9, 12 mg) spiked with 25 µL

```{r 4-loading test, echo = FALSE, message=FALSE}

#path:
data_path = "./data/Test4"

# Load the dataset
data4 <- read.csv(file.path(data_path,"Data_cort_values_method_ALL.csv"))
data4 <- data4 %>%
  filter(!Sample %in% c("B0", "BE", "NSB", "POOL")) 
data <- data4
data$Failed_samples[is.na(data$Failed_samples)] <- "OK"
cat(paste("Data stored in path", data_path, "has", nrow(data), "data points", sep= " "))
```

### Results
```{r 4-results-boxplot, echo = FALSE}
# Save result
cat("Results:")
head(data[,c("Sample", "Final_pg.mg_A", "Final_pg.mg_B", "Final_pg.mg_C")])
write.csv(data, file.path(data_path, "Data_Cortisol_Processed.csv"), row.names = FALSE)
data4<-data

# View summary
cat("Summary of final values for each calculation method")
cat("Method A:")
summary(data$Final_pg.mg_A)
cat("Method B:")
summary(data$Final_pg.mg_B)
cat("Method C:")
summary(data$Final_pg.mg_C)

# Reshape from wide to long format
data_long <- data %>%
  select(Final_pg.mg_A, Final_pg.mg_B, Final_pg.mg_C) %>%
  pivot_longer(
    cols = everything(),
    names_to = "Method",
    values_to = "pg_mg"
  )

# Optional: clean group names for prettier x-axis labels
data_long$Group <- gsub("Final_pg.mg_", "", data_long$Method)

# Plot boxplots
ggplot(data_long, aes(x = Group, y = pg_mg, fill = Method)) +
  geom_boxplot(outlier.shape = 21, outlier.fill = "white", outlier.color = "black") +
  labs(
    title = "Test4: Final values using calculation methods A, B, and C",
    x = "Method",
    y = "pg/mg"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

```

```{r 4-results-scatterplot, echo = FALSE}

# Reshape data for plotting
data_long <- data %>%
  pivot_longer(
    cols = c(Final_pg.mg_A, Final_pg.mg_B, Final_pg.mg_C),
    names_to = "Method",
    values_to = "Final_pg.mg"
  )

ggplot(data_long, aes(x = Sample, y = Final_pg.mg, color = Method, group = Method)) +
  geom_line(aes(group = Sample), color = "gray75", size = 0.5) +
  geom_point(size = 2.8, alpha = 0.7, position = position_dodge(width=0.5)) +
  scale_color_manual(
    values = c("Final_pg.mg_A" = "steelblue",
               "Final_pg.mg_B" = "orange",
               "Final_pg.mg_C" = "darkgreen"),
    labels = c("Method A (Traditional)",
               "Method B (Nist et al.)",
               "Method C (Sam's)")
  ) +
  labs(
    title = "Hair Cortisol by Sample and Calculation Method",
    x = "Sample ID",
    y = "Final Cortisol (pg/mg)",
    color = "Method"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    legend.position = "top"
  )


```


```{r 4-results-A and C, echo =FALSE}

# Reshape to long format
data_long <- data %>%
  pivot_longer(
    cols = c(Final_pg.mg_A, Final_pg.mg_C),
    names_to = "Method",
    values_to = "Final_pg.mg"
  )

# Plot with lines connecting A and C values for each sample
ggplot(data_long, aes(x = Sample, y = Final_pg.mg, color = Method, group = Method)) +
  geom_line(aes(group = Sample), linewidth = 0.6, color = "gray70") +  # light line connecting methods
  geom_point(size = 2.8, alpha = 0.8, position = position_dodge(width = 0.5)) +
  scale_color_manual(
    values = c("Final_pg.mg_A" = "steelblue", "Final_pg.mg_C" = "darkgreen"),
    labels = c("Method A", "Method C")
  ) +
  labs(
    title = "Comparing final values obtained using 2 methods, by Sample",
    x = "Sample ID",
    y = "Final Cortisol Concentration (pg/mg)",
    color = "Calculation Method"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    legend.position = "top"
  )

```


```{r}
# Filter to include only good quality samples
data_ok <- data %>%
    filter(!is.na(Binding.Perc)) %>%
  filter(Failed_samples == "OK")

# Reshape data for plotting
data_long_ok <- data_ok %>%
  pivot_longer(
    cols = c(Final_pg.mg_A, Final_pg.mg_C),
    names_to = "Method",
    values_to = "Final_pg.mg"
  )

head(data_long_ok)
# Plot for OK samples only
ggplot(data_long_ok, aes(x = Sample, y = Final_pg.mg, color = Method)) +
  geom_line(aes(group = Sample), color = "gray75", size = 0.5) +
  geom_point(size = 3, alpha = 0.8, position = position_dodge(width = 0.5)) +
  scale_color_manual(
    values = c("Final_pg.mg_A" = "steelblue",
               "Final_pg.mg_B" = "orange",
               "Final_pg.mg_C" = "darkgreen"),
    labels = c("Method A (Basic)",
               "Method B (Subtraction + x2)",
               "Method D (Spike contribution)")
  ) +
  labs(
    title = "Hair Cortisol (Good Samples Only) — Test4",
    x = "Sample ID",
    y = "Final Cortisol (pg/mg)",
    color = "Method"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    legend.position = "top"
  )
summary(data_ok$Final_pg.mg_C)
```


# Test3

**Plate description**

Combined variables to evaluate effect of weight, dilution, and addition of spike



```{r test3, echo = TRUE}
#path:
data_path  = "./data/Test3"

# Load the dataset
data3 <- read.csv(file.path(data_path,"Data_QC_flagged.csv"))
data<-data3
data$Failed_samples[is.na(data$Failed_samples)] <- "OK"
# Conversion and Constants
data$Buffer_ml <- data$Buffer_nl / 1000
data$TotalVol_well_ml <- data$TotalVol_well_ul / 1000
data$SpikeVol_ml <- data$SpikeVol_ul / 1000

# Extraction ratio
extraction <- 1 / 0.75

# Spike concentration (pg/mL)
std_conc <- 3139.5

# Method A: No spike correction
data$Final_pg.mg_A <- ((data$Ave_Conc_pg.ml / data$Weight_mg) *
                         extraction * data$Buffer_ml * data$Dilution)

# Method B: Subtract spike reading (std) and apply dilution factor (×2)
data$Final_pg.mg_B <- ifelse(
  data$Spike == 1,
  ((data$Ave_Conc_pg.ml - std_conc) / data$Weight_mg) *
    extraction * data$Buffer_ml * 2,
  # fallback to method A if not spiked
 data$Final_pg.mg_A
)

# Method C: Spike contribution subtracted
data$Spike_Contribution <- ((data$SpikeVol_ml * std_conc) / data$TotalVol_well_ml) / data$Dilution
summary(data$Spike_Contribution)

data$Final_pg.mg_C <- (
  (data$Ave_Conc_pg.ml - data$Spike_Contribution) / data$Weight_mg) *
    extraction * data$Buffer_ml * data$Dilution


# Save result
write.csv(data, file.path(data_path,"Data_Cortisol_Processed.csv"), row.names = FALSE)

# View summary
summary(data$Final_pg.mg_A)
summary(data$Final_pg.mg_B)
summary(data$Final_pg.mg_C)

data3 <- data
```


```{r}

# Reshape data for plotting
data_long <- data %>%
  pivot_longer(
    cols = c(Final_pg.mg_A, Final_pg.mg_B, Final_pg.mg_C),
    names_to = "Method",
    values_to = "Final_pg.mg"
  )

ggplot(data_long, aes(x = Sample, y = Final_pg.mg, color = Method, group = Method)) +
  geom_line(aes(group = Sample), color = "gray75", size = 0.5) +
  geom_point(size = 3, alpha = 0.8, position = position_dodge(width = 0.5)) + 
  scale_color_manual(
    values = c("Final_pg.mg_A" = "steelblue",
               "Final_pg.mg_B" = "orange",
               "Final_pg.mg_C" = "darkgreen"),
    labels = c("Method A (Traditional)",
               "Method B (Subtraction + x2)",
               "Method C (Spike contribution)")
  ) +
  labs(
    title = "Hair Cortisol by Sample and Calculation Method",
    x = "Sample ID",
    y = "Final Cortisol (pg/mg)",
    color = "Method"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    legend.position = "top"
  )


```


```{r}
# Reshape to long format
data_long <- data %>%
  pivot_longer(
    cols = c(Final_pg.mg_A, Final_pg.mg_C),
    names_to = "Method",
    values_to = "Final_pg.mg"
  )

# Plot

# Plot with lines connecting A and D values for each sample
ggplot(data_long, aes(x = Sample, y = Final_pg.mg, color = Method)) +
  geom_line(aes(group = Sample), color = "gray75", size = 0.5) +  # light line connecting methods
  geom_point(size = 3, alpha = 0.8, position = position_dodge(width = 0.5)) +
  scale_color_manual(
    values = c("Final_pg.mg_A" = "steelblue", 
               "Final_pg.mg_C" = "darkgreen"),
    labels = c("Method A", "Method C")
  ) +
  labs(
    title = "Hair Cortisol Concentration by Sample",
    x = "Sample ID",
    y = "Final Cortisol (pg/mg)",
    color = "Calculation Method"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    legend.position = "top"
  )
```


```{r}
# Filter to include only good quality samples
data_ok <- data %>%
  filter(Failed_samples == "OK")

# Reshape data for plotting
data_long_ok <- data_ok %>%
  pivot_longer(
    cols = c(Final_pg.mg_A, Final_pg.mg_C),
    names_to = "Method",
    values_to = "Final_pg.mg"
  )

print(data_long_ok, n=5)

# Plot for OK samples only
ggplot(data_long_ok, aes(x = Sample, y = Final_pg.mg, color = Method)) +
  geom_line(aes(group = Sample), color = "gray75", size = 0.5) +
  geom_point(size = 3, alpha = 0.8, position = position_dodge(width = 0.5)) +
  scale_color_manual(
    values = c("Final_pg.mg_A" = "steelblue",
             #  "Final_pg.mg_B" = "orange",
               "Final_pg.mg_C" = "darkgreen"),
    labels = c("Method A (Traditional)",
              # "Method B (Subtraction + x2)",
               "Method C (Spike contribution)")
  ) +
  labs(
    title = "Hair Cortisol (Good Samples Only) — Test3",
    x = "Sample ID",
    y = "Final Cortisol (pg/mg)",
    color = "Method"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    legend.position = "top"
  )

```


# evaluation test4 (method C)

```{r}
# Load the dataset
df <- data4

# Clean data 
df <- df %>% filter(!is.na(Final_pg.mg_C), !Sample %in% c("NSB", "Blank", "B0"))

# Set factors for plotting and grouping
df$Dilution_samplef <- as.factor(df$Dilution_sample)
df$Category <- as.factor(df$Category)

# 1. === PARALLELISM TEST ===
# Plot concentration vs. dilution to check for proportional decrease

ggplot(df, aes(x = log10(as.numeric(Dilution_sample)), y = Final_pg.mg_C , color = Category)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Parallelism Test", x = "Log10(Dilution_sample)", y = "Final Cortisol (pg/mg)")

# Optional: Run ANOVA for parallelism by slope comparison
parallel_model <- lm(Final_pg.mg_C  ~ log10(Dilution_sample) * Category, data = df)
summary(parallel_model)
```
Term	Estimate	p-value	Interpretation
(Intercept)	35.08	1.7e-05	Baseline value for TA at no dilution
CategoryC	–19.89	0.0473 *	TC starts significantly lower than TA
CategoryD	–18.70	0.0612 .	TD also starts lower, marginally significant
CategoryP	–15.34	0.0517 .	TP slightly lower, borderline significant
Interaction (log10 × CategoryB)	+17.33	0.0598 .	TB's slope is steeper than TA (marginal)

TC and TD show parallel dilution curves relative to TA, suggesting you can safely apply Method D.

TB may have a steeper slope, suggesting spiking only the first tube might amplify dilution effect slightly.


```{r plot parallelism_binding}
ggplot(df, aes(x = log10(as.numeric(Dilution_sample)), y = Binding.Perc , color = Category)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Parallelism Test", x = "Log10(Dilution_sample)", y = "Binding %")

# Optional: Run ANOVA for parallelism by slope comparison
parallel_model <- lm(Binding.Perc  ~ log10(Dilution_sample) * Category, data = df)
summary(parallel_model)

```

Term	Estimate	p-value	Interpretation
(Intercept)	11.70	0.0081 **	Baseline binding % for Category A (TA) at no dilution
log10(Dilution_sample)	49.88	1.6e-13 ***	Strong increase in binding % with increasing dilution
CategoryB	4.71	0.424	TB baseline slightly higher than TA, not significant
CategoryC	10.10	0.093 .	TC baseline marginally higher than TA
CategoryD	6.19	0.295	TD not significantly different from TA at baseline
CategoryP	7.94	0.093 .	TP marginally higher binding at baseline
log10(Dilution_sample):CategoryB	–4.66	0.391	TB slope not significantly different from TA
log10(Dilution_sample):CategoryC	–3.19	0.556	TC slope ≈ TA
log10(Dilution_sample):CategoryD	–0.36	0.947	TD slope ≈ TA 

 Strong Main Effect of Dilution
Binding % increases significantly with higher dilution (p < 0.001).

This is expected: lower concentration = higher % binding in competitive ELISA.

2. No Significant Interaction Terms
The interaction terms (slope differences) are not significant (all p > 0.39).

This means the binding curves across all categories are parallel.

3. Intercept Differences (Baseline Shift)
Some categories (notably TC and TP) start with higher binding %, but this is only marginally significant (p ≈ 0.09).

This suggests potential small matrix effects, but not enough to invalidate comparison.

```{r}

# 3. === ACCURACY TEST ===
# If you have expected values, compare to observed

# Example expected values for some spiked standards (you can edit this!)
expected_vals <- tibble(
  Sample = c("STD1", "STD2", "STD3"),
  Expected_pg.mg = c(30, 15, 7.5)  # replace with your known expected values
)

# Join expected to observed and compute error
accuracy_df <- df %>%
  inner_join(expected_vals, by = "Sample") %>%
  mutate(
    AbsError = abs(Final_pg.mg_C  - Expected_pg.mg),
    RelError = AbsError / Expected_pg.mg * 100
  )

# Plot observed vs expected
ggplot(accuracy_df, aes(x = Expected_pg.mg, y = Final_pg.mg_C )) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = 2) +
  labs(title = "Accuracy: Observed vs Expected", x = "Expected (pg/mg)", y = "Observed (pg/mg)")



# Log buffer as dilution proxy
df$log_dilution <- log10(df$Dilution_sample)

# Parallelism test for TA vs TC
df_sub <- df %>% filter(Category %in% c("A", "C"))

model_parallel <- lm(Final_pg.mg_C ~ log_dilution * Category, data = df_sub)
summary(model_parallel)

```

Term	Estimate	p-value	Interpretation
(Intercept)	35.08	0.0003	Cortisol for TA at dilution = 1 (log10 = 0)
log_dilution	1.58	0.794	Slope of dilution for TA — not significant
CategoryC	–19.89	0.052 .	TC starts ~20 pg/mg lower than TA — borderline significant
Interaction (log_dilution:CategoryC)	9.44	0.282	TC slope vs TA — not significant → ✅ parallel slopes

🔍 Parallelism holds: no significant difference in slope between TA and TC (p = 0.282)

⚠️ Intercept difference between TA and TC is borderline significant (p = 0.052)

TC starts lower than TA, suggesting a shift in baseline cortisol, but dilution behavior is similar


```{r}

# Filter dataset to include only TA (A) and TC (C)
df_sub <- df %>%
  filter(Category %in% c("A", "C")) %>%
  mutate(
    Category = factor(Category, levels = c("A", "C")),
    log_dilution = log10(Dilution_sample)
  )

# Plot
ggplot(df_sub, aes(x = log_dilution, y = Final_pg.mg_C, color = Category)) +
    geom_smooth(method = "lm", se = TRUE, linewidth = 1.2, alpha = 0.3) +
  geom_point(size = 3, alpha = 0.8) +

  labs(
    title = "Parallelism Test: TA vs TC",
    subtitle = "Final Cortisol (pg/mg) vs Log10(Dilution) with 95% CI",
    x = "Log10(Dilution Sample)",
    y = "Final Cortisol (pg/mg)",
    color = "Category"
  ) +
  scale_color_manual(
    values = c("A" = "steelblue", "C" = "darkgreen"),
    labels = c("TA (Non-Spiked)", "TC (All Dilutions Spiked)")
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "top"
  )


```
If slope ≈ 0 and variance is low → good precision.

You can also compute %CV across replicates.
```{r}

# Load your data

# Extract meaningful category label
df$Category <- str_extract(df$Sample, "^T[ABCD]")

# Keep only A–D dilution categories
df <- df %>% filter(Category %in% c("TA", "TB", "TC", "TD"))

# Create log dilution
df$log_dilution <- log10(df$Dilution_sample)

# All pairwise category combinations
pairs <- combn(unique(df$Category), 2, simplify = FALSE)

# Loop and test each pair for both variables
for (pair in pairs) {
  sub_df <- df %>% filter(Category %in% pair)
  pair_label <- paste(pair, collapse = "_vs_")
  
  ### 1. Final Values Model
  model_final <- lm(Final_pg.mg_C ~ log_dilution * Category, data = sub_df)
  p_final <- tidy(model_final) %>% 
    filter(str_detect(term, "log_dilution:Category")) %>%
    pull(p.value)
  
  ### 2. Binding % Model
  model_binding <- lm(Binding.Perc ~ log_dilution * Category, data = sub_df)
  p_bind <- tidy(model_binding) %>% 
    filter(str_detect(term, "log_dilution:Category")) %>%
    pull(p.value)
  
  ### Plot for Final Values
p1 <- ggplot(sub_df, aes(x = log_dilution, y = Final_pg.mg_C, color = Category)) +
   geom_smooth(method = "lm", se = TRUE, alpha = 0.3) +  
  geom_point(size = 2) +
   
    labs(
      title = paste("Final Values –", pair_label),
      subtitle = paste("Interaction p =", round(p_final, 4)),
      x = "log10(Dilution)", y = "Final Cortisol (pg/mg)"
    ) +
    theme_minimal() +
    theme(plot.title = element_text(face = "bold"))
  print(p1)
  
  ### Plot for Binding %
p2 <- ggplot(sub_df, aes(x = log_dilution, y = Binding.Perc, color = Category)) +
   geom_smooth(method = "lm", se = TRUE, alpha = 0.3) + 
   geom_point(size = 2) +

    labs(
      title = paste("Binding % –", pair_label),
      subtitle = paste("Interaction p =", round(p_bind, 4)),
      x = "log10(Dilution)", y = "Binding (%)"
    ) +
    theme_minimal() +
    theme(plot.title = element_text(face = "bold"))
  print(p2)
  
  ### Print results to console
  cat("\n=== ", pair_label, " ===\n")
  cat("Interaction p (Final values):", round(p_final, 4), "\n")
  cat("Interaction p (Binding %):   ", round(p_bind, 4), "\n")
  }

```
Comparison	Final Values p	Binding % p	Interpretation
TA vs TB	0.164	0.381	Not significantly different slopes. Likely parallel.

TA vs TC	0.366	0.604	Parallel; spiking all tubes in TC doesn't distort slope much.

TA vs TD	0.951	0.928	Extremely parallel — almost identical slopes.
TB vs TC	0.479	0.845	No significant slope difference. Spike methods act similarly.

TB vs TD	0.162	0.471	Slight trend in slope difference, but still not statistically significant.

TC vs TD	0.367	0.674	Parallel. Spiking either all tubes (TC) or just first tube (TD) gives similar dilution response.

All p-values are > 0.05, meaning there is no strong evidence of non-parallelism.

This suggests your serial dilutions are behaving consistently, even with different spiking strategies.

The fact that binding percentage curves are also parallel confirms this is not an artifact of back-calculation — it's real behavior at the assay level.

```{r}
# === Load and prepare data ===
df <- data4 %>%
  mutate(Category = str_extract(Sample, "^T[ABCD]")) %>%
  filter(Category %in% c("TA", "TB", "TC", "TD")) %>%
  mutate(log_dilution = log10(Dilution_sample))

# === Updated and safe function ===
extract_intercepts_with_pval <- function(model, response_label) {
  model_tidy <- tidy(model, conf.int = TRUE)
  intercept_ta <- model_tidy %>% filter(term == "(Intercept)") %>% pull(estimate)

  intercepts <- model_tidy %>%
    filter(term == "(Intercept)" | str_detect(term, "Category")) %>%
    mutate(
      Category = case_when(
        term == "(Intercept)" ~ "TA",
        str_detect(term, "TB") ~ "TB",
        str_detect(term, "TC") ~ "TC",
        str_detect(term, "TD") ~ "TD"
      ),
      Estimate = if_else(Category == "TA", estimate, intercept_ta + estimate),
      CI_low = if_else(Category == "TA", conf.low, conf.low + intercept_ta),
      CI_high = if_else(Category == "TA", conf.high, conf.high + intercept_ta),
      P_Value = if_else(Category == "TA", NA_real_, p.value),
      Variable = response_label
    ) %>%
    dplyr::select(Variable, Category, Estimate, CI_low, CI_high, P_Value)

  return(intercepts)
}

# === Fit models ===
mod_final <- lm(Final_pg.mg_C ~ log_dilution + Category, data = df)
mod_binding <- lm(Binding.Perc ~ log_dilution + Category, data = df)

# === Extract intercepts ===
intercepts_final <- extract_intercepts_with_pval(mod_final, "Final Cortisol (pg/mg)")
intercepts_binding <- extract_intercepts_with_pval(mod_binding, "Binding Percentage")

# === Combine and reshape for table ===
intercepts_all <- bind_rows(intercepts_final, intercepts_binding)


# === View final table ===
print(intercepts_final)

cat("TB (only first tube spiked) behaves almost identically to TA (non-spiked) → good parallelism, no signal distortion.

TC (every tube spiked) lowers the intercept but not significantly.

TD (1:1 spike + dilution) significantly suppresses signal, indicating likely dilution or matrix effects.")

print(intercepts_binding)

cat("TB again tracks closely with TA, confirming consistent assay response.

TC and TD show increased binding, which is unusual — spiking may be blocking binding sites or altering matrix effects.

The higher binding % may explain the lower final cortisol values, especially in TD")

# === Plot: Intercepts with CI ===
ggplot(intercepts_all, aes(x = Category, y = Estimate, color = Variable)) +
  geom_point(position = position_dodge(width = 0.5), size = 4) +
  geom_errorbar(aes(ymin = CI_low, ymax = CI_high), 
                width = 0.2, position = position_dodge(width = 0.5)) +
  labs(
    title = "Intercept Estimates for TA–TD",
    subtitle = "With 95% Confidence Intervals",
    y = "Intercept Value",
    x = "Category"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))

```




```{r test4 pairs}
# Step 1: Create sample pairs
# e.g., base = TA, spiked = TB with similar Sample ID patterns

# Simulate pairing by shared SampleID 
df <- data4 

# Step 1: Extract TA and TB and sample ID
df_pair <- df %>%
  filter(!is.na(Ave_Conc_pg.ml))  %>%
  filter(Category %in% c("A", "D")) %>%
  mutate(SampleID = str_extract(Sample, "\\d+$"))

# Step 2: Pivot to wide format
df_wide <- df_pair %>%
  dplyr::select(SampleID, Category, Ave_Conc_pg.ml, Spike_Contribution) 
df_wide <- df_wide %>%
  pivot_wider(names_from = Category, values_from = c(Ave_Conc_pg.ml, Spike_Contribution))


# Step 4: Calculate recovery
head(df_wide)
temp <- df_wide %>%
  mutate(Recovery_pct = ((Ave_Conc_pg.ml_D - Ave_Conc_pg.ml_A) / Spike_Contribution_D) * 100)

# Step 5: Plot
ggplot(temp, aes(x = SampleID, y = Recovery_pct)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_hline(yintercept = c(80, 120), linetype = "dashed", color = "darkred") +
  labs(
    title = "Spike Recovery at ELISA Level (pg/mL)",
    x = "Sample ID (TA/TD pair)",
    y = "Recovery (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

reduces detection due to interference or over-saturation. If spike volume is large (e.g. 110 µL into 110 µL sample), it can dilute the original signal below the unspiked concentration

State in your results that “Recovery for some high-spike samples was negative, indicating likely signal suppression from matrix effects or over-spiking.”

Use parallelism to back up your conclusion:

If slope is parallel but intercept drops, it's further evidence of baseline suppression

Several spiked samples exhibited negative recovery percentages, indicating that measured cortisol concentrations were lower than their unspiked counterparts. This likely reflects signal suppression due to matrix effects or over-dilution from high spike volumes, particularly in the TD group, where spike-to-sample ratios were highest. These results highlight the importance of accounting for spike-related suppression in final quantification strategies.


```{r}

# Simulate pairing by shared SampleID (you may need to adjust this step)
df <- data4 

# Step 1: Extract TA and TB and sample ID
df_pair <- df %>%
  filter(!is.na(Ave_Conc_pg.ml))  %>%
  filter(Category %in% c("A", "C")) %>%
  mutate(SampleID = str_extract(Sample, "\\d+$"))

# Step 2: Pivot to wide format
df_wide <- df_pair %>%
  dplyr::select(SampleID, Category, Ave_Conc_pg.ml, Spike_Contribution) 
df_wide <- df_wide %>%
  pivot_wider(names_from = Category, values_from = c(Ave_Conc_pg.ml, Spike_Contribution))


# Step 4: Calculate recovery
temp <- df_wide %>%
  mutate(Recovery_pct = ((Ave_Conc_pg.ml_C - Ave_Conc_pg.ml_A) / Spike_Contribution_C) * 100)

# Step 5: Plot
ggplot(temp, aes(x = SampleID, y = Recovery_pct)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_hline(yintercept = c(80, 120), linetype = "dashed", color = "darkred") +
  labs(
    title = "Spike Recovery at ELISA Level (pg/mL)",
    x = "Sample ID (TA/TC pair)",
    y = "Recovery (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

# Recovery Test4

```{r recov test4}


# Simulate pairing by shared SampleID (you may need to adjust this step)
df <- data4 

# Step 1: Extract TA and TB and sample ID
df_pair <- df %>%
  filter(!is.na(Ave_Conc_pg.ml))  %>%
  filter(Category %in% c("A", "B")) %>%
  mutate(SampleID = str_extract(Sample, "\\d+$"))

# Step 2: Pivot to wide format
df_wide <- df_pair %>%
  dplyr::select(SampleID, Category, Ave_Conc_pg.ml, Spike_Contribution) 
df_wide <- df_wide %>%
  pivot_wider(names_from = Category, values_from = c(Ave_Conc_pg.ml, Spike_Contribution))


# Step 4: Calculate recovery
temp <- df_wide %>%
  mutate(Recovery_pct = ((Ave_Conc_pg.ml_B - Ave_Conc_pg.ml_A) / Spike_Contribution_B) * 100)

# Step 5: Plot
ggplot(temp, aes(x = SampleID, y = Recovery_pct)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_hline(yintercept = c(80, 120), linetype = "dashed", color = "darkred") +
  labs(
    title = "Spike Recovery at ELISA Level (pg/mL)",
    x = "Sample ID (TA/TB pair)",
    y = "Recovery (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


# Recovery test 3

```{r}
library(dplyr)
# Load the datax
df <- read.csv(file.path(data_path, "Data_Cortisol_Processed.csv"))
data3_processed <- df
# Clean: extract numeric SampleID suffix to help match pairs
df <- df %>%
  mutate(SampleID = str_extract(samp_comparable, "\\d+$"))

# Step 1: Wide format - match NoSpike and YesSpike using SampleID
df_wide <- df %>%
  filter(Category %in% c("NoSpike", "YesSpike")) %>%
  dplyr::select(SampleID, Category, Ave_Conc_pg.ml)

# Step 3: Identify IDs that have BOTH NoSpike and YesSpike
df_avg <- df_wide %>%
  dplyr::group_by(SampleID, Category) %>%
  dplyr::summarise(Ave_pgml = mean(Ave_Conc_pg.ml, na.rm = TRUE), .groups = "drop")

# Step 3: Identify IDs that have BOTH NoSpike and YesSpike
paired_ids <- df_avg %>%
  dplyr::count(SampleID) %>%
  filter(n == 2) %>%
  pull(SampleID)


df_paired <- df_avg %>%
  filter(SampleID %in% paired_ids)

df_recovery <- df_paired %>%
  pivot_wider(names_from = Category, values_from = Ave_pgml)

# Step : Define known spike contribution (pg/mL)
# Assume 25 µL of 3200 pg/mL added into 50 µL total = (25/1000 * 3200) / (50/1000)
known_spike_pgml <- 1569.75  # = 1600 pg/mL

df_recovery <- df_recovery %>%
  mutate(Recovery_pct = ((YesSpike - NoSpike) / known_spike_pgml) * 100)

df_recovery <- df_recovery %>%
  mutate(Recovery_Class = case_when(
      Recovery_pct < 80 ~ "Under-recovery",
      Recovery_pct > 120 ~ "Over-recovery",
      TRUE ~ "Acceptable"))

# Step 5: Plot
ggplot(df_recovery, aes(x = SampleID, y = Recovery_pct, fill = Recovery_Class)) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = c(80, 120), linetype = "dashed", color = "darkred") +
  scale_fill_manual(values = c(
    "Under-recovery" = "red",
    "Acceptable" = "steelblue",
    "Over-recovery" = "orange2"
  )) +
  labs(
    title = "Spike Recovery (%) at ELISA Level",
    subtitle = "Dashed lines show 80–120% acceptable range",
    x = "Sample ID",
    y = "Recovery (%)",
    fill = "Recovery Classification"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Step 4: View or export summary table
print(df_recovery)

```
All samples show recovery ≥ 105%, with most between 105% and 132%

Sample 5, 8, 9, and 11–12 exceed the standard acceptable range of 80–120%

This suggests slightly inflated recovery, potentially due to:

Minor pipetting differences

Matrix effects (e.g., enhanced absorbance in spiked matrix)

Slight overestimation in YesSpike values relative to expected spike contribution


Spike recovery ranged from 105% to 155% across 10 matched sample pairs. Most samples fell near or slightly above the commonly accepted 80–120% range, with the highest recovery observed in Sample 5 (155%). These results indicate that the ELISA assay successfully detects added cortisol with high sensitivity, though minor over-recovery may reflect matrix effects or variation in sample absorbance. Overall, recovery was consistent and supports the validity of the spike-in approach at the ELISA level.



# Precision and accuracy, test3

```{r}
df <- data3_processed

# Step 1: Clean and filter only relevant categories
df_sub <- df %>%
  filter(Category %in% c("NoSpike", "YesSpike")) %>%
  mutate(samp_comparable = as.character(samp_comparable))

# Step 2: Keep only samp_comparable IDs with both YesSpike and NoSpike
valid_pairs <- df_sub %>%
  distinct(samp_comparable, Category) %>%
  dplyr::count(samp_comparable) %>%
  filter(n == 2) %>%
  pull(samp_comparable)

df_matched <- df_sub %>%
  filter(samp_comparable %in% valid_pairs)

# Step 3: Pivot to wide format for recovery calculation
df_wide <- df_matched %>%
  dplyr::select(samp_comparable, Category, Ave_Conc_pg.ml) 

df_avg <- df_wide %>%
  dplyr::group_by(samp_comparable, Category) %>%
  dplyr::summarise(Ave_pgml = mean(Ave_Conc_pg.ml, na.rm = TRUE), .groups = "drop")

Spike_Contribution <- 1569.75

df_recovery <- df_avg %>%
  pivot_wider(names_from = Category, values_from = Ave_pgml)


# Step 4: Calculate Recovery % and accuracy flag
df_wide <- df_recovery %>%
  mutate(
    Recovery_pct = ((YesSpike - NoSpike) / Spike_Contribution) * 100,
    Accuracy_Flag = case_when(
      is.na(Recovery_pct) ~ NA_character_,
      Recovery_pct < 80 ~ "Under-recovery",
      Recovery_pct > 120 ~ "Over-recovery",
      TRUE ~ "Acceptable"
    )
  )

# Step 5: Extract precision values
df_precision <- df %>%
  dplyr::select(Sample, samp_comparable, CV.Perc, Weight_mg, Buffer_ml) %>%
  mutate(Precision_Flag = case_when(
    is.na(CV.Perc) ~ NA_character_,
    CV.Perc <= 15 ~ "Acceptable",
    TRUE ~ "High CV"
  ))

df_precision$samp_comparable<- as.character(df_precision$samp_comparable)
# Step 6: Merge precision with accuracy summary
df_summary <- left_join(df_wide, df_precision, by = "samp_comparable") %>%
  distinct(samp_comparable, .keep_all = TRUE) %>%
  dplyr::select(Sample, Weight_mg, Buffer_ml, CV.Perc, Precision_Flag, Recovery_pct, Accuracy_Flag)

df_sorted <- df_summary %>% arrange(Weight_mg, Buffer_ml)
df_sorted$Sample <- 1:nrow(df_sorted)
# Step 7: View or export
print(df_sorted)


# Optional: Save to file
write.csv(df_sorted, file.path(data_path, "precision_accuracy_summary.csv"), row.names = FALSE)

ggplot(df_sorted, aes(x = Weight_mg, y = Recovery_pct,
                      color = Accuracy_Flag, shape = Precision_Flag)) +
  geom_point(size = 4) +
  geom_hline(yintercept = c(80, 120), linetype = "dashed", color = "darkgray") +
  labs(
    title = "Spike Recovery (%) vs Hair Weight (mg)",
    subtitle = "Dashed lines show 80–120% acceptable range",
    x = "Hair Weight (mg)",
    y = "Recovery (%)",
    color = "Accuracy",
    shape = "Precision"
  ) +
  theme_minimal()           
           


```

