---
title: "Cortisol Concentration Values, Test4"
author: "Paloma Contreras"
date: "`r Sys.Date()`"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

# Summary

**Data Cleaning and Quality Control (QC)** details how files are loaded, merged, and cleaned, including the exclusion of unnecessary columns and handling of missing values.

**Cortisol value calculations** 

- **Standard Method (Method A)**: 
- **Spike-Corrected Method (Method B)**: 

**Results**:  
Inter-assay CV: 21% (Bindings for 20mg sample diluted in 250 uL, no spike: 64.8% and 48% in test3 and test4, respectively)

Intra-assay CV: 14.5% 

Intra-assay CV after removing low quality samples: 10%


**Conclusions**: 




**Concerns**
Overall quality of the plate is not great, but serial dilusions show clear parallelism and standards have values within the expected


```{r echo = FALSE, warning=FALSE, message=FALSE}
# Install libraries

library(knitr)
library(ggplot2)
library(broom)
library(paletteer)
library(dplyr)
data_path = "./data/Test4"
```

# Set parameters

```{r}
# flag samples with high CV (15%) or binding above 80% and under 20%
CV_threshold <- 15.0
uppBinLim <- 80.0
lowBinLim <- 20.0
# define volume of methanol used for cortisol extraction
# vol added / vol recovered (mL)
extraction <- 1/0.750

# set reading value of spike (std1, 0.333 ug/dL), 
# and transforming to ug.dL

std <- (3191+3228)/2
std.r <- (std/10000)
std.r

# according to chatgpt, this is the spike contribution:
# 1600 pg/mL, which is very similar to half of the reading
```

# Data Cleaning and QC

Load, inspect and merge 3 files:

- layout: 5 columns (Wells, Sample, weight_mg, buffer_nl, spike), 96 rows
- results: from myassays.com (not including standards), 82 rows

```{r loading files, echo = FALSE}
# LAYOUT 

layout <- read.csv(file.path(data_path,"layout_wells_test4_021925.csv"), 
                   stringsAsFactors = TRUE, 
                   na.strings = c("", " "))
dim(layout)
kable(head(layout)) 

# RESULTS  

results <- read.csv(file.path(data_path,"myassays_table_test4_021925.csv"), 
                    stringsAsFactors = TRUE, 
                    na.strings = c("", " ", "-"))

results <- results[2:length(results)]

dim(results)
kable(head(results)) 

```

```{r}

# Merge files

m <- merge(layout, results, by = "Wells")

colnames(m) <- c("Wells", "Sample", "Category", 
                "Weight_mg", "Buffer_nl", "Spike", 
                "SpikeVol_uL", "Dilution", "Raw.OD", 
                 "Binding.Perc", "Conc_pg/ml",
                 "Ave_Conc_pg/ml", "CV.Perc", 
                 "SD", "SEM") 
m[, 4:12] <- lapply(m[, 4:12], 
                    function(x) as.numeric(as.character(x)))
m <- m[order(m$Sample),]
kable(tail(m)) 

```

### Duplicates with high CV
Identify and flag samples with high coefficient of variation (duplicate measurements that are too different from each other)
```{r}
#create new file
m1 <- m %>%
  mutate(CV_categ = ifelse(CV.Perc > CV_threshold, 
                           "HIGH CV", NA))
cv_high <- m1 %>% 
  filter(CV.Perc > CV_threshold) %>% 
  arrange(desc(CV.Perc))

kable(cv_high)
cat("High CV in a total of", nrow(cv_high), "duplicates")
print(cv_high[2])

```

### Samples outside the curve
Samples that have a binding percentage over 80 or 20 do not provide accurate results, and we consider them to be outside the curve. 
```{r}
# flag samples with binding percentage over 80 or under 20
m2 <- m1 %>%
  mutate(Binding.Perc_categ = ifelse(Binding.Perc > uppBinLim, "ABOVE 80% binding", 
                                     ifelse(Binding.Perc < lowBinLim, "UNDER 20% binding", 
                                            NA)))

out_curve <- m2 %>% 
  filter(Binding.Perc < uppBinLim | Binding.Perc > lowBinLim)
kable(out_curve)

```

### Total samples failed

```{r}
# dataset with failed samples flagged
data.flagged <- m2 %>%
  mutate(Failed_samples = ifelse(!is.na(CV_categ) & !is.na(Binding.Perc_categ), 
                             paste(CV_categ, Binding.Perc_categ, sep = ";"), 
                             coalesce(CV_categ, Binding.Perc_categ))) 


kable(tail(data.flagged))
write.csv(data.flagged, file.path(data_path, "Data_QC_flagged.csv"), 
          row.names = FALSE) 

# table with samples that failed
failed_samples <- data.flagged[!is.na(data.flagged$Failed_samples),]
write.csv(failed_samples, file.path(data_path, "failed_samples.csv"), 
          row.names = FALSE) 
nrow(failed_samples)

# dataset with failed samples removed
data.no_failed <- m2 %>% 
 filter(CV.Perc < CV_threshold) %>%
 filter(Binding.Perc > lowBinLim & Binding.Perc < uppBinLim ) 
 
write.csv(data.no_failed, file.path(data_path, "Data_QC_filtered.csv"), row.names = FALSE) 

cat("Number of failed samples is", nrow(failed_samples))
cat("Number of good quality data points is", nrow(data.no_failed))
```

# Cortisol concentration calculation

Loading files and transforming units, *including low quality data*

```{r setup, include=TRUE, message=FALSE}
df <- read.csv(file.path(data_path,"Data_QC_flagged.csv"))
kable(head(df))
# remove outlier
df<- df[(df$Sample != "TP3A"),]

# Transform to μg/dl from assay output
df$Ave_Conc_ug.dL <- c(df$Ave_Conc_pg.ml/10000)

# Creating variables in indicated units
# dilution (buffer)
df$Buffer_ml <- c(df$Buffer_nl/1000)

# remove unnecessary information 
data <- df %>%
    dplyr::select(Sample, Category, Binding.Perc, Weight_mg, Buffer_ml, Spike, Ave_Conc_ug.dL, Ave_Conc_pg.ml, Failed_samples) 

kable(head(data, 10))
dim(data)

# remove duplicates
data <- data[!is.na(data$Binding.Perc), ]

```

## (A) Standard Calculation

Formula: 

((A/B) * (C/D) * E * 10,000) = F 

- A = μg/dl from assay output;
- B = weight (in mg) of hair subjected to extraction;
- C = vol. (in ml) of methanol added to the powdered hair;
- D = vol. (in ml) of methanol recovered from the extract and subsequently dried down;
- E = vol. (in ml) of assay buffer used to reconstitute the dried extract;
- F = final value of hair CORT Concentration in pg/mg.


```{r}
##### Calculate final values #####
data$Final_conc_pg.mg <- c(
    (data$Ave_Conc_ug.dL / data$Weight_mg) * # A/B *
      extraction *                                  # C/D  *     
      data$Buffer_ml * 10000)                 # E * 10000
data <- data[order(data$Sample),]
write.csv(data, file.path(data_path, "Data_cort_values_methodA.csv"), row.names = F)

# summary for all samples
summary(data$Final_conc_pg.mg)

kable(head(data, 10))
dim(data)

```

## (B) Accounting for Spike

We followed the procedure described in **Nist et al. 2020**:

"Thus, after pipetting 25μL of standards and samples into the appropriate wells of the 96-well assay plate, we added 25μL of the 0.333ug/dL standard to all samples,
resulting in a 1:2 dilution of samples. The remainder of the manufacturer’s protocol was
unchanged. We analyzed the assay plate in a Powerwave plate reader (BioTek, Winooski,
VT) at 450nm and subtracted background values from all assay wells. In the calculations, we
subtracted the 0.333ug/dL standard reading from the sample readings. Samples that resulted
in a **negative number were considered nondetectable**. We converted cortisol levels from
ug/dL, as measured by the assay, to pg/mg—based on the mass of hair collected and
analyzed using the following formula:

A/B * C/D * E * 10,000 * 2 = F

where 
- A = μg/dl from assay output; 
- B = weight (in mg) of collected hair; 
- C = vol. (in ml) of methanol added to the powdered hair; 
- D = vol. (in ml) of methanol recovered from the extract and subsequently dried down; 
- E = vol. (in ml) of assay buffer used to reconstitute the dried extract; 10,000 accounts for changes in metrics; 2 accounts for the dilution factor after addition of the spike; and 
- F = final value of hair cortisol concentration in pg/mg"


```{r}
dSpike <- data

##### Calculate final values #####

dSpike$Final_conc_pg.mg <- 
  ifelse(
    dSpike$Spike == 1,    ## Only spiked samples
      ((dSpike$Ave_Conc_ug.dL - std.r) / # (A-spike) / B
      dSpike$Weight_mg) 
    * extraction *      # C / D
      dSpike$Buffer_ml * 10000 * 2 ,    # E * 10000 *2
    dSpike$Final_conc_pg.mg  
)

write.csv(dSpike, file.path(data_path, "Data_cort_values_methodB.csv"), row.names = F)

# summary for all samples
summary(dSpike$Final_conc_pg.mg)


dSpikeSub <- data[c(data$Spike == 0), ]
summary(dSpikeSub$Final_conc_pg.mg)

kable(head(dSpike, 10))
```

## (C) Skip unit transformation


```{r}
data$Final_conc_pg.mg <- c(
    (data$Ave_Conc_pg.ml / data$Weight_mg) * # A/B *
      extraction *                                  # C/D  *     
      data$Buffer_ml)                 # E 
datac <- data[order(data$Sample),]
write.csv(datac, file.path(data_path, "Data_cort_values_methodC.csv"), row.names = F)

# summary for all samples
summary(datac$Final_conc_pg.mg)

```

## (D) Account for Spike (contribution / 2)

Spike contribution (pg/mL) = (Vol. spike (mL) x Conc. spike (pg) ) / Vol. reconstitution (mL)
```{r}

# Calculate contribution of spike according to the different volumes in which it was added
# considere that contribution in serial dilutions is smaller 

#datac$Spike.cont_pg.mL <-  datac

dSpiked <- datac
dSpiked$Final_conc_pg.mg <- 
  ifelse(
    dSpike$Spike == 1,    ## Only spiked samples
      ((dSpike$Ave_Conc_pg.ml - (std/2)) / # (A-spike) / B
      dSpike$Weight_mg) 
    * extraction *      # C / D
      dSpike$Buffer_ml,    # E *  *2
    dSpike$Final_conc_pg.mg  
)

write.csv(dSpiked, file.path(data_path, "Data_cort_values_methodD.csv"), row.names = F)

# summary for all samples
summary(dSpiked$Final_conc_pg.mg)
```


# Plots 

## (A) Standard Calculation

```{r fig.width=6, fig.height=7}
# scatterplot method A
data$Spike <- replace(data$Spike, data$Spike == 1, 'Yes')
data$Spike <- replace(data$Spike, data$Spike == 0, 'No')
data$Buffer <- data$Buffer_ml
data$Buffer <- replace(data$Buffer, data$Buffer == 0.06, '60 uL')
data$Buffer <- replace(data$Buffer, data$Buffer == 0.11, '110 uL')
data$Buffer <- replace(data$Buffer, data$Buffer == 0.25, '250 uL')


ggplot(data, aes(y = Final_conc_pg.mg, 
                 x = Weight_mg, 
                 color = Spike,
                 shape = Buffer)) +
  geom_point(size = 2.5, alpha = 0.85) +  
   geom_text(aes(label = Sample), size = 2.5, vjust = -0.65, hjust = -0.18) +
    theme_minimal() +  
  geom_hline(yintercept = 0, 
             linetype = "dashed", color = "red") +
  xlim(0,52) +
  labs(
    title = "(A) Standard Calculation Cortisol Values",
    y = "Final Concentration (pg/mg)",
    x = "Weight (mg)") + 
  theme(
    plot.title = element_text(hjust = 0.5, 
                              size = 17, face = "bold"),
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12)  
  ) + 
  scale_color_paletteer_d("vangogh::CafeTerrace")
```

## (B) Accounting for Spike
```{r fig.width=6, fig.height=7}

dSpike$Spike <- replace(dSpike$Spike, dSpike$Spike == 1, 'Yes')
dSpike$Spike <- replace(dSpike$Spike, dSpike$Spike == 0, 'No')
dSpike$Buffer <- dSpike$Buffer_ml
dSpike$Buffer <- replace(dSpike$Buffer, dSpike$Buffer == 0.06, '60 uL')
dSpike$Buffer <- replace(dSpike$Buffer, dSpike$Buffer == 0.11, '110 uL')
dSpike$Buffer <- replace(dSpike$Buffer, dSpike$Buffer == 0.25, '250 uL')

# scatterplot
ggplot(dSpike, aes(y = Final_conc_pg.mg, 
                 x = Weight_mg, 
                 color = Spike,
                 shape = Buffer)) +
  geom_point(size = 3.5,  alpha = 0.85) +  
  geom_text(aes(label = Sample), size = 3, vjust = -1, hjust = -0.1) +
  theme_minimal() +  
  xlim(0,52) +
  geom_hline(yintercept = 0, 
             linetype = "dashed", color = "red") +
  labs(
    title = "(B) Calculation Accounting for Spike",
    y = "Final Concentration (pg/mg)",
    x = "Weight (mg)" ) +
  theme(
    plot.title = element_text(hjust = 0.5, 
                              size = 17, face = "bold"),
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12)  
  )+ 
  scale_color_paletteer_d("vangogh::CafeTerrace")

```

## (C) 
```{r fig.width=6, fig.height=7}
# scatterplot method c
datac$Spike <- replace(datac$Spike, data$Spike == 1, 'Yes')
datac$Spike <- replace(datac$Spike, data$Spike == 0, 'No')
datac$Buffer <- data$Buffer_ml
datac$Buffer <- replace(datac$Buffer, data$Buffer == 0.06, '60 uL')
datac$Buffer <- replace(datac$Buffer, data$Buffer == 0.11, '110 uL')
datac$Buffer <- replace(datac$Buffer, data$Buffer == 0.25, '250 uL')


ggplot(datac, aes(y = Final_conc_pg.mg, 
                 x = Weight_mg, 
                 color = Spike,
                 shape = Buffer)) +
  geom_point(size = 2.5, alpha = 0.85) +  
   geom_text(aes(label = Sample), size = 2.5, vjust = -0.65, hjust = -0.18) +
    theme_minimal() +  
  geom_hline(yintercept = 0, 
             linetype = "dashed", color = "red") +
    #ylim(-26,24) +
#  xlim(0,52) +
  labs(
    title = "(C) ",
    y = "Final Concentration (pg/mg)",
    x = "Weight (mg)") + 
  theme(
    plot.title = element_text(hjust = 0.5, 
                              size = 17, face = "bold"),
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12)  
  ) + 
  scale_color_paletteer_d("vangogh::CafeTerrace")
```

## D
```{r fig.width=6, fig.height=7}

dSpiked$Spike <- replace(dSpiked$Spike, dSpiked$Spike == 1, 'Yes')
dSpiked$Spike <- replace(dSpiked$Spike, dSpiked$Spike == 0, 'No')
dSpiked$Buffer <- dSpiked$Buffer_ml
dSpiked$Buffer <- replace(dSpiked$Buffer, dSpiked$Buffer == 0.06, '60 uL')
dSpiked$Buffer <- replace(dSpiked$Buffer, dSpiked$Buffer == 0.11, '110 uL')
dSpiked$Buffer <- replace(dSpiked$Buffer, dSpiked$Buffer == 0.25, '250 uL')

# scatterplot
ggplot(dSpiked, aes(y = Final_conc_pg.mg, 
                 x = Weight_mg, 
                 color = Spike,
                 shape = Buffer)) +
  geom_point(size = 3.5,  alpha = 0.85) +  
  geom_text(aes(label = Sample), size = 3, vjust = -1, hjust = -0.1) +
  theme_minimal() +  
    ylim(-26,30) +
  xlim(0,52) +
  geom_hline(yintercept = 0, 
             linetype = "dashed", color = "red") +
  labs(
    title = "(D) ",
    y = "Final Concentration (pg/mg)",
    x = "Weight (mg)" ) +
  theme(
    plot.title = element_text(hjust = 0.5, 
                              size = 17, face = "bold"),
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12)  
  )+ 
  scale_color_paletteer_d("vangogh::CafeTerrace")

```

# Evaluation 

```{r message=FALSE}
# non-spiked samples only
data2 <-data

#two datasets, separated by dilution
data2.06 <- data2[data2$Buffer == "60 uL", ]
data2.11 <- data2[data2$Buffer == "110 uL", ]
data2.25 <- data2[data2$Buffer == "250 uL", ]


#### fit models ####

# model Buffer = 0.06
model06 <- lm(Final_conc_pg.mg ~ Weight_mg, 
              data = data2.06)
r_squared06 <- summary(model06)$r.squared

# model Buffer = 0.25
model25 <- lm(Final_conc_pg.mg ~ Weight_mg, 
              data = data2.25)
r_squared25 <- summary(model25)$r.squared

# Calculate residuals
residuals06 <- residuals(model06)
residuals25 <- residuals(model25)

# Quantify residuals
# Mean Absolute Error
mae06 <- mean(abs(residuals06))          
# Standard Deviation of Residuals
std_dev06 <- sd(residuals06)   

# Mean Absolute Error
mae25 <- mean(abs(residuals25))      
# Standard Deviation of Residuals
std_dev25 <- sd(residuals25)                      



# scatterplot

ggplot(data2, aes(y = Final_conc_pg.mg, 
                  x = Weight_mg, 
                  color = Category, 
                  fill = Category)) +
  geom_point(size = 2.5) +  
  geom_text(label = c(data2$Sample), nudge_y = 0.75, nudge_x = -0.5) +
  geom_smooth(method = "lm", 
              color = "gold3", 
              se = TRUE,
              alpha = 0.1) + 
  geom_hline(yintercept = mean(data2$Final_conc_pg.mg), 
             color = "gray80",
             linetype = "dashed") +
  geom_hline(yintercept = mean(data2.06$Final_conc_pg.mg), 
             color = "lightblue3",
             linetype = "dashed") +
  geom_hline(yintercept = mean(data2.25$Final_conc_pg.mg), 
             color = "lightpink3",
             linetype = "dashed") +
  theme_minimal() +  
  xlim(5, max(data2$Weight_mg) + 4) +
  ylim(0, max(data2$Final_conc_pg.mg)+4) + 
  labs(
    title = "Final Cort Concentration and Weight
    (Non-spiked only)",
    y = "Final Concentration (pg/mg)",
    x = "Weight (mg)"  
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12) 
  ) +
  # Add R^2 annotation
  annotate("text", x = max(data2$Weight_mg) * 0.7, 
           y = min(data2$Final_conc_pg.mg) * 1.5,
           label = paste("R² =", round(r_squared06, 3)), 
           size = 5, color = "black") +
  annotate("text", x = max(data2$Weight_mg) * 0.7, 
           y = max(data2$Final_conc_pg.mg) * 0.84,
           label = paste("R² =", round(r_squared25, 3)), 
           size = 5, color = "black")

```

The previous figure shows that: 

- results are very stable across weights, particularly for the samples where a dilution of 250 uL was used 
- there is more error when using a dilution of 60 uL   
- dilution affects estimation of cortisol concentration in a significant way: even though final concentration numbers account for differences in the dilutions, the results we observe for each group do not overlap
- the average value when using 250 uL of buffer is twice as big as when using 60 uL


## Optimal dilution

**Error using 0.06 mL buffer**
```{r echo = FALSE}
# Print the results
cat("Mean Absolute Error (MAE) 0.06 mL:", round(mae06, 3), "\n")
cat("Standard Deviation of Residuals 0.06 mL:", round(std_dev06, 3), "\n")
```
**Error using 0.25 mL buffer**
```{r echo = FALSE}
cat("Mean Absolute Error (MAE) 0.25 mL:", round(mae25, 3), "\n") 
cat("Standard Deviation of Residuals 0.25 mL:", round(std_dev25, 3), "\n")

## Abs error and std dev. are larger for dilution 0.06 mL
```
From this we conclude that using **a 250 uL dilution provides more consistent results**

```{r echo = FALSE, include = FALSE}
# wflow_publish("../analysis/ELISA_Computation.Rmd")

```
