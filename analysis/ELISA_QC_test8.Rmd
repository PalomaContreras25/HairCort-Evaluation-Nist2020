---
title: "QC_ELISA 8"
author: "Paloma"
date: "`r Sys.Date()`"
output: workflowr::wflow_html
editor_options: 
  chunk_output_type: console
---

Here I show how files are loaded, merged, and cleaned, including the exclusion of unnecessary columns and handling of missing values.


```{r echo = FALSE, warning=FALSE, message=FALSE}
# Install libraries

data_path = "./data/Test8"
library(ggplot2)
library(broom)
library(paletteer)
library(here)
options(scipen = 999)
library(knitr)
library(dplyr)
library(tidyverse)

```

# Set parameters

```{r}
# flag samples with high CV (15%) or binding above 80% and under 20%
CV_threshold <- 15.0
uppBinLim <- 80.0
lowBinLim <- 20.0
```

# Data Cleaning and QC

Load, inspect and merge 3 files:

- layout: 7 columns (Wells, Sample, weight_mg, buffer_nl, spike, volume of the spike, dilution factor), -- rows
- results: from myassays.com (not including standards), -- rows

```{r loading files, echo = FALSE}

# LAYOUT 
layout <- read.csv(file.path(data_path,"layout_wells_test8_090225.csv"), 
                   stringsAsFactors = TRUE, 
                   na.strings = c("", " "))
dim(layout)
kable(head(layout,4)) 

# RESULTS  
results <- read.csv(file.path(data_path,"myassays_table_test8_090225.csv"), 
                    stringsAsFactors = TRUE, 
                    na.strings = c("", " ", "-"))
results <- results[2:length(results)]
dim(results)
kable(head(results,4)) 

```

Merge data set and improve formatting: 
```{r echo = FALSE, warning=FALSE}

# Merge files
m <- merge(layout, results, by = "Wells")

m <- m %>%
  rename(
    OD = Raw,
    Binding.Perc = X.,
    Conc_pg.ml = Conc., 
    Ave_Conc_pg.ml = Conc...Average.,
    CV.Perc = X.CV 
  )

# reorder columns
m <- m %>%
  select(1:3, Person, everything()) %>% 
  mutate(Conc_pg.ml = na_if(Conc_pg.ml, "< Curve"),
         Conc_pg.ml = na_if(Conc_pg.ml, "> Curve"))

# Make numeric all cols except first five
m[, 5:length(m)] <- lapply(m[, 5:length(m)], 
                    function(x) as.numeric(as.character(x)))
m <- m[order(m$Sample),]
kable(m[c(11, 12, 13, 22, 23), ]) 


```


Will not calculate CV. Will do it using final values (accounting for differences in weight, dilution, etc).


### Samples outside the curve
Samples that have a binding percentage over 80 or 20 do not provide accurate results, and we consider them to be outside the curve. 
```{r, echo = FALSE}
# flag samples with binding percentage over 80 or under 20
m2 <- m %>%
  mutate(Binding.Perc_categ = ifelse(Binding.Perc > uppBinLim, "ABOVE 80% binding", 
                                     ifelse(Binding.Perc < lowBinLim, "UNDER 20% binding", 
                                            NA)))

out_curve <- m2[!is.na(m2$Binding.Perc_categ), ] 

cat(paste("Total samples outside the curve:", nrow(out_curve), "(some are blanks or NSB)", sep=" "))
print(out_curve[2])
#kable(out_curve[,c("Sample", "Category", "Weight_mg", "Buffer_nl", "Dilution_sample", "Raw.OD", "Binding.Perc", "Conc_pg.ml", "Ave_Conc_pg.ml", "CV.Perc", "CV_categ", "Binding.Perc_categ")])

```

### Total samples failed

```{r echo = FALSE}
# dataset with failed samples flagged

write.csv(m2, file.path(data_path, "Data_QC_flagged.csv"), 
          row.names = FALSE) 


#cat("Number of failed samples is", nrow(failed_samples))
#cat("Number of good quality data points is", nrow(data.no_failed))

```
Location
```{r echo= FALSE}
#cat("Good quality data is stored in Data_QC_filtered.csv file")
cat("Data set with low quality samples flagged: Data_QC_flagged.csv")

```

Overall quality of the assay
```{r echo = FALSE, warning=FALSE}

#temp <- data.flagged[!is.na(data.flagged$CV.Perc),]
#temp2 <- temp %>%
  #filter(Sample != c("B0", "BE", 
   #                 "NSB"))

#CVraw <- round(mean(temp2$CV.Perc), 2)
#CV <- round(mean(data.no_failed$CV.Perc), 2)
#cat("Intra-Assay CV including all samples is", CVraw, "%")
#cat("Intra-Assay CV including only good quality data is", CV, "%, for a total of", nrow(data.no_failed), "samples")
```


