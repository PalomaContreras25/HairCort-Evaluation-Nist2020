---
title: "QC_ELISA 9"
author: "Paloma"
date: "`r Sys.Date()`"
output: workflowr::wflow_html
editor_options: 
  chunk_output_type: console
---

Here I show how files are loaded, merged, and cleaned, including the exclusion of unnecessary columns and handling of missing values.


- Intra-Assay CV:  **  % **

- Intra-Assay CV after removing low quality data: ** -% m**

- Good quality data points: ** - **

```{r echo = FALSE, warning=FALSE, message=FALSE}
# Install libraries

data_path = "./data/Test9"
library(knitr)
library(tidyverse)
library(dplyr)
```

# Set parameters

```{r}
# flag samples with high CV (15%) or binding above 80% and under 20%
CV_threshold <- 15.0
uppBinLim <- 80.0
lowBinLim <- 20.0
```

# Data Cleaning and QC

Load, inspect and merge 3 files:

- layout: 7 columns (Wells, Sample, weight_mg, buffer_nl, spike, volume of the spike, dilution factor), -- rows
- results: from myassays.com (not including standards), -- rows

```{r loading files, echo = FALSE}
# LAYOUT 

layout <- read.csv(file.path(data_path, "layout_wells_test9_251008.csv"), 
                   stringsAsFactors = TRUE, 
                   na.strings = c("", " "))
dim(layout)
kable(head(layout,4)) 

# RESULTS  

results <- read.csv(file.path(data_path,"myassays_table_test9_251008.csv"), 
                    stringsAsFactors = TRUE, 
                    na.strings = c("", " ", "-"))
results <- results[2:length(results)]
dim(results)
kable(head(results,4)) 

```

Merged dataset: 
```{r echo = FALSE, warning=FALSE}

# Merge files
m <- merge(layout, results, by = "Wells")

m <- m %>%
  dplyr::rename(
    OD = Raw.OD,
    Binding.Perc = X.,
    Conc_pg.ml = Conc., 
    Ave_Conc_pg.ml = Conc...Average.,
    CV.Perc = X.CV 
  )

# reorder columns
m <- m %>%
  dplyr::select(1:3, Person, Sub_categ, everything()) %>% 
  dplyr::select(-SD, -SEM, -Num_strands, -CV.Perc) 

# Make numeric all cols except first five
m[, 6:length(m)] <- lapply(m[, 6:length(m)], 
                    function(x) as.numeric(as.character(x)))
m <- m[order(m$Sample),]
kable(m[c(11, 12, 13, 22, 23), ]) 

```


```{r echo = FALSE}
# flag samples with binding percentage over 80 or under 20
m2 <- m %>%
  mutate(Binding.Perc_categ = ifelse(Binding.Perc > uppBinLim, "ABOVE 80% binding", 
                                     ifelse(Binding.Perc < lowBinLim, "UNDER 20% binding", 
                                            NA)))

out_curve <- m2[!is.na(m2$Binding.Perc_categ), ] 

cat(paste("Total samples outside the curve:", nrow(out_curve), "(some are blanks or NSB)", sep=" "))
print(out_curve[2])
```


```{r echo = FALSE}
# dataset with failed samples flagged

write.csv(m2, file.path(data_path, "Data_QC_flagged.csv"), 
          row.names = FALSE) 


#cat("Number of failed samples is", nrow(failed_samples))
#cat("Number of good quality data points is", nrow(data.no_failed))

```
Location
```{r echo= FALSE}
#cat("Good quality data is stored in Data_QC_filtered.csv file")
cat("Data set with low quality samples flagged: Data_QC_flagged.csv")

```
