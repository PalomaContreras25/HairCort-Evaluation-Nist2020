---
title: "QC_ELISA 4"
output: html_document
date: "2025-04-02"
---

Here I show how files are loaded, merged, and cleaned, including the exclusion of unnecessary columns and handling of missing values.


- Intra-Assay CV:  **11.28 %**

- Intra-Assay CV after removing low quality data: **4.76 %**

- Good quality data points: **19**

```{r echo = FALSE, warning=FALSE, message=FALSE}
# Install libraries

data_path = "./data/Test4"
library(knitr)
library(dplyr)
```

# Set parameters

```{r}
# flag samples with high CV (15%) or binding above 80% and under 20%
CV_threshold <- 15.0
uppBinLim <- 80.0
lowBinLim <- 20.0
```

# Data Cleaning and QC

Load, inspect and merge 3 files:

- layout: 7 columns (Wells, Sample, weight_mg, buffer_nl, spike, volume of the spike, dilution factor), 96 rows
- results: from myassays.com (not including standards), 82 rows

```{r loading files, echo = FALSE}
# LAYOUT 

layout <- read.csv(file.path(data_path,"layout_wells_test4_021925.csv"), 
                   stringsAsFactors = TRUE, 
                   na.strings = c("", " "))
#dim(layout)
#kable(head(layout)) 

# RESULTS  

results <- read.csv(file.path(data_path,"myassays_table_test4_021925.csv"), 
                    stringsAsFactors = TRUE, 
                    na.strings = c("", " ", "-"))

results <- results[2:length(results)]

#dim(results)
#kable(head(results)) 

```

Merged dataset: 
```{r echo = FALSE, warning=FALSE}

# Merge files

m <- merge(layout, results, by = "Wells")

colnames(m) <- c("Wells", "Sample", "Category", 
                "Weight_mg", "Buffer_nl", "Spike", 
                "SpikeVol_uL", "Dilution_sample", "Dilution_spike", "Vol_in_well.tube_uL", "Extraction_ratio", "Raw.OD",  
                 "Binding.Perc", "Conc_pg/ml",
                 "Ave_Conc_pg/ml", "CV.Perc", 
                 "SD", "SEM") 
m[, 4:12] <- lapply(m[, 4:12], 
                    function(x) as.numeric(as.character(x)))
m <- m[order(m$Sample),]
kable(m[c(10, 12, 14, 16, 24, 26, 28), ]) 

```

### Duplicates with high CV
Flag samples with high coefficient of variation (duplicate measurements that are too different from each other)
```{r echo = FALSE}
#create new file
m1 <- m %>%
  mutate(CV_categ = ifelse(CV.Perc > CV_threshold, 
                           "HIGH CV", NA))
cv_high <- m1 %>% 
  filter(CV.Perc > CV_threshold) %>% 
  arrange(desc(CV.Perc))

#kable(cv_high)
cat("High CV in a total of", nrow(cv_high), "duplicates. These are:")
print(cv_high[2])

```

### Samples outside the curve
Samples that have a binding percentage over 80 or 20 do not provide accurate results, and we consider them to be outside the curve. 
```{r, echo = FALSE}
# flag samples with binding percentage over 80 or under 20
m2 <- m1 %>%
  mutate(Binding.Perc_categ = ifelse(Binding.Perc > uppBinLim, "ABOVE 80% binding", 
                                     ifelse(Binding.Perc < lowBinLim, "UNDER 20% binding", 
                                            NA)))

out_curve <- m2[!is.na(m2$Binding.Perc_categ), ]

cat(paste("Total samples outside the curve:", nrow(out_curve), "(some are blanks or NSB)", sep=" "))
#kable(out_curve)

```

### Total samples failed

```{r echo = FALSE}
# dataset with failed samples flagged
data.flagged <- m2 %>%
  mutate(Failed_samples = ifelse(!is.na(CV_categ) & !is.na(Binding.Perc_categ), 
                             paste(CV_categ, Binding.Perc_categ, sep = ";"), 
                             coalesce(CV_categ, Binding.Perc_categ))) 


kable(tail(data.flagged))
write.csv(data.flagged, file.path(data_path, "Data_QC_flagged.csv"), 
          row.names = FALSE) 


# table with samples that failed
failed_samples <- data.flagged[!is.na(data.flagged$Failed_samples),]
write.csv(failed_samples, file.path(data_path, "failed_samples.csv"), 
          row.names = FALSE) 

# dataset with failed samples removed
data.no_failed <- m2 %>% 
 filter(CV.Perc < CV_threshold) %>%
 filter(Binding.Perc > lowBinLim & Binding.Perc < uppBinLim ) 
 
write.csv(data.no_failed, file.path(data_path, "Data_QC_filtered.csv"), row.names = FALSE) 

cat("Number of failed samples is", nrow(failed_samples))
cat("Number of good quality data points is", nrow(data.no_failed))

```
Location
```{r echo= FALSE}
cat("Good quality data is stored in Data_QC_filtered.csv file")
cat("Data set with low quality samples flagged: Data_QC_flagged.csv")

```

Overall quality of the assay
```{r echo = FALSE, warning=FALSE}


temp <- data.flagged[!is.na(data.flagged$CV.Perc),]
temp2 <- temp %>%
  filter(Sample != c("B0", "BE", 
                    "NSB"))

CVraw <- round(mean(temp2$CV.Perc), 2)
CV <- round(mean(data.no_failed$CV.Perc), 2)
cat("Intra-Assay CV including all samples is", CVraw, "%")
cat("Intra-Assay CV including only good quality data is", CV, "%, for a total of", nrow(data.no_failed), "samples")
```


