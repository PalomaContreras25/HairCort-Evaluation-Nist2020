---
title: "Cortisol Concentration Values"
author: "Paloma Contreras"
date: "2024-10-16"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

# Summary

**Data Cleaning and Quality Control (QC)** details how files are loaded, merged, and cleaned, including the exclusion of unnecessary columns and handling of missing values.

**Cortisol value calculations** were conducted using two methods:

- **Standard Method (Method A)**: Calculates cortisol concentration without correction for spiked samples.
- **Spike-Corrected Method (Method B)**: Adjusts for spiked samples to account for addition of a known amount of cortisol, following Nist et al. 2020.

**Results**: As we see below, the formula used by Nist et al. results in negative values, which would mean that there is no cortisol in original samples. 

<table>
Summary                      Nist et al.     My samples      Non-spiked only
---------------          -------------  -------------    -----------------
Mean cort conc (pg/mg)   23.74          -0.18              7.9 
Range cort conc (pg/mg)  2.1 to 124.9*   -29.3 to 11.76     2.71 to 11.76
Weight range (mg)        0.4 to 10.9     11 to 37.1        12 to 37
Sample size              X              30                 18
                                                             
</table>

This could be an artifact of an extremely high absorbance level. Non-spiked samples, however, result in values that are within the range found in similar studies of cortisol in human hair. After accounting for differences in dilution and weight, our results suggest some optimal parameters. 


**Conclusions**: 

- Dilution of 250uL is preferable over 60uL 
- Non-spiked samples seem to generate expected results


**Concerns**

- Spike results in unrealistic values
- Could be explained by the higher weight of our samples 
- Dilution of 250uL results in values that are twice as big as with 60uL, but they should be very similar or at least overlap


```{r echo = FALSE, warning=FALSE, message=FALSE}
# Install libraries


library(ggplot2)
library(broom)
library(paletteer)
library(knitr)
library(dplyr)
```

# Data Cleaning and QC

Load, inspect and merge 3 files:

- layout
- results 
- information about each sample

```{r}

data_path = "./data/Test3"
# LAYOUT 

layout <- read.csv(file.path(data_path,"layout_wells_test3_091524.csv"), 
                   stringsAsFactors = TRUE, 
                   na.strings = c("", " "))
kable(head(layout)) 

# RESULTS  

results <- read.csv(file.path(data_path, "myassays_table_test3_091524.csv"), 
                    stringsAsFactors = TRUE, 
                    na.strings = c("", " ", "-"))
results <- results[ ,c(2:length(results))]

kable(head(results)) 


# INFO

info <- read.csv(file.path(data_path, "sample_info_test3_091524.csv"), 
                 stringsAsFactors = TRUE, 
                 na.strings = c("", " "))
info <- info[ ,c(1:5)]
kable(head(info)) 

```


```{r}

# Merge files

m <- merge(layout, results, by = "Wells")
m <- merge(m, info, by = c("Sample", "Wells"))
m <- na.omit(m)
colnames(m) <- c("Sample", "Wells", "Raw.OD", 
                 "Binding.Perc", "Conc_pg/ml",
                 "Ave_Conc_pg/ml", "CV.Perc", 
                 "SD", "SEM", "Weight_mg", "Buffer_nl", 
                 "Spike") 
m[, 3:11] <- lapply(m[, 3:11], 
                    function(x) as.numeric(as.character(x)))
kable(head(m)) 

```


### Duplicates with high CV
Identify and flag samples with high coefficient of variation (duplicate measurements that are too different from each other)
```{r}
# flag samples with high CV (15%)

CV_threshold <- 15.0

#create new file
m1 <- m %>%
  mutate(CV_categ = ifelse(CV.Perc > CV_threshold, 
                           "HIGH CV", "NA"))
cv_high <- m1 %>% 
  filter(CV.Perc > CV_threshold) %>% 
  arrange(desc(CV.Perc))

kable(cv_high)

```

### Samples outside the curve
Samples that have a binding percentage over 80 or 20 do not provide accurate results, and we consider them to be outside the curve. 
```{r}

# flag samples with binding percentage over 80 or under 20
m2 <- m1 %>%
  mutate(Binding.Perc_categ = ifelse(Binding.Perc > 80, "ABOVE 80% binding", 
                                     ifelse(Binding.Perc < 20, "UNDER 20% binding", 
                                            NA)))
out_curve <- m2 %>% 
  filter(Binding.Perc < 20.0 | Binding.Perc > 80.0) %>% 
  arrange(desc(Binding.Perc))
kable(out_curve)

```

### Total samples failed

```{r}
# dataset with failed samples flagged
data.flagged <- m2 %>%
  mutate(Failed_samples = ifelse(!is.na(CV_categ) & !is.na(Binding.Perc_categ), 
                             paste(CV_categ, Binding.Perc_categ, sep = ";"), 
                             coalesce(CV_categ, Binding.Perc_categ))) %>%
  select(!c(CV_categ, Binding.Perc_categ))

write.csv(data.flagged, file.path(data_path, "Data_QC_flagged.csv"), 
          row.names = FALSE) 

# table with samples that failed
failed_samples <- data.flagged[!is.na(data.flagged$Failed_samples),]
write.csv(failed_samples, file.path(data_path, "failed_samples.csv"), 
          row.names = FALSE) 
nrow(failed_samples)

# dataset with failed samples removed
data.no_failed <- m2 %>% 
 filter(CV.Perc < CV_threshold) %>%
 filter(Binding.Perc > 20 & Binding.Perc < 80 ) 

data.no_failed <- data.no_failed[,c(1:13)]
 
write.csv(data.no_failed, file.path(data_path, "Data_QC_filtered.csv"), row.names = FALSE) 
```

Number of failed samples is 8 (out of 38)

# Cortisol concentration calculation

Loading files and transforming units

```{r setup, include=TRUE, message=FALSE}
df <- read.csv(
  file.path(data_path,"Data_QC_filtered.csv"))

# Transform to μg/dl from assay output
df$Ave_Conc_ug.dL <- c(df$Ave_Conc_pg.ml/10000)

# Creating variables in indicated units
# dilution (buffer)
df$Buffer_ml <- c(df$Buffer_nl/1000)

# remove unnecessary information 
data <- df %>% 
  filter(CV.Perc < 15) %>% 
  filter(Binding.Perc < 80 & Binding.Perc > 20) %>%
    dplyr::select(Sample, Binding.Perc, Weight_mg, Buffer_ml, Spike, Ave_Conc_ug.dL) 

kable(head(data, 10))
```

## (A) Standard Calculation

Formula: 

((A/B) * (C/D) * E * 10,000) = F 

- A = μg/dl from assay output;
- B = weight (in mg) of hair subjected to extraction;
- C = vol. (in ml) of methanol added to the powdered hair;
- D = vol. (in ml) of methanol recovered from the extract and subsequently dried down;
- E = vol. (in ml) of assay buffer used to reconstitute the dried extract;
- F = final value of hair CORT Concentration in pg/mg.


```{r}

##### Calculate final values #####
data$Final_conc_pg.mg <- c(
    (data$Ave_Conc_ug.dL / data$Weight_mg) * # A/B *
      1.3/1 *                                  # C/D  *     
      data$Buffer_ml * 10000)                 # E * 10000

write.csv(data, file.path(data_path, "Data_cort_values_methodA.csv"), row.names = F)

# summary for all samples
summary(data$Final_conc_pg.mg)

kable(head(data, 10))
```

## (B) Accounting for Spike

We followed the procedure described in **Nist et al. 2020**:

"Thus, after pipetting 25μL of standards and samples into the appropriate wells of the 96-well assay plate, we added 25μL of the 0.333ug/dL standard to all samples,
resulting in a 1:2 dilution of samples. The remainder of the manufacturer’s protocol was
unchanged. We analyzed the assay plate in a Powerwave plate reader (BioTek, Winooski,
VT) at 450nm and subtracted background values from all assay wells. In the calculations, we
subtracted the 0.333ug/dL standard reading from the sample readings. Samples that resulted
in a **negative number were considered nondetectable**. We converted cortisol levels from
ug/dL, as measured by the assay, to pg/mg—based on the mass of hair collected and
analyzed using the following formula:

A/B * C/D * E * 10,000 * 2 = F

where 
- A = μg/dl from assay output; 
- B = weight (in mg) of collected hair; 
- C = vol. (in ml) of methanol added to the powdered hair; 
- D = vol. (in ml) of methanol recovered from the extract and subsequently dried down; 
- E = vol. (in ml) of assay buffer used to reconstitute the dried extract; 10,000 accounts for changes in metrics; 2 accounts for the dilution factor after addition of the spike; and 
- F = final value of hair cortisol concentration in pg/mg"


```{r}
dSpike <- data
# reading standard 1 (0.333 ug/dL), 
# and transforming to ug.dL
std.r <- ((3133 + 3146)/2)/10000
std.r

##### Calculate final values #####

dSpike$Final_conc_pg.mg <- 
  ifelse(
    dSpike$Spike == 1,    ## Only spiked samples
      (dSpike$Ave_Conc_ug.dL - std.r) / # (A-spike) / B
      dSpike$Weight_mg * 1.3 / 1 *      # C / D
      dSpike$Buffer_ml * 10000 * 2 ,    # E * 10000 *2
    dSpike$Final_conc_pg.mg  
)

write.csv(dSpike, file.path(data_path, "Data_cort_values_methodB.csv"), row.names = F)

# summary for all samples
summary(dSpike$Final_conc_pg.mg)

# summary only for non-spiked samples
dSpikeSub <- dSpike [ dSpike$Spike == 0, ]
summary(dSpikeSub$Final_conc_pg.mg)

kable(head(dSpike, 10))
```

# Plots 

## (A) Standard Calculation

```{r}
# scatterplot method A
data$Spike <- replace(data$Spike, data$Spike == 1, 'Yes')
data$Spike <- replace(data$Spike, data$Spike == 0, 'No')
data$Buffer <- data$Buffer_ml
data$Buffer <- replace(data$Buffer, data$Buffer == 0.06, '60 uL')
data$Buffer <- replace(data$Buffer, data$Buffer == 0.25, '250 uL')


ggplot(data, aes(y = Final_conc_pg.mg, 
                 x = Weight_mg, 
                 color = Spike,
                 shape = Buffer)) +
  geom_point(size = 3.5) +  
  xlim(5, max(data$Weight_mg)+4) + 
  ylim(0, max(data$Final_conc_pg.mg)+4) + 
    theme_minimal() +  
  labs(
    title = "(A) Standard Calculation Cortisol Values",
    y = "Final Concentration (pg/mg)",
    x = "Weight (mg)") + 
  theme(
    plot.title = element_text(hjust = 0.5, 
                              size = 17, face = "bold"),
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12)  
  ) + 
  scale_color_paletteer_d("vangogh::CafeTerrace")
```

## (B) Accounting for Spike
```{r}

dSpike$Spike <- replace(dSpike$Spike, dSpike$Spike == 1, 'Yes')
dSpike$Spike <- replace(dSpike$Spike, dSpike$Spike == 0, 'No')
dSpike$Buffer <- dSpike$Buffer_ml
dSpike$Buffer <- replace(dSpike$Buffer, dSpike$Buffer == 0.06, '60 uL')
dSpike$Buffer <- replace(dSpike$Buffer, dSpike$Buffer == 0.25, '250 uL')

# scatterplot
ggplot(dSpike, aes(y = Final_conc_pg.mg, 
                 x = Weight_mg, 
                 color = Spike,
                 shape = Buffer)) +
  geom_point(size = 3.5) +  
  xlim(5, max(dSpike$Weight_mg)+4) + 
  ylim(min(dSpike$Final_conc_pg.mg)-2,
       max(dSpike$Final_conc_pg.mg)+2) + 
  theme_minimal() +  
  geom_hline(yintercept = 0, 
             linetype = "dashed", color = "red") +
  labs(
    title = "(B) Calculation Accounting for Spike",
    y = "Final Concentration (pg/mg)",
    x = "Weight (mg)" ) +
  theme(
    plot.title = element_text(hjust = 0.5, 
                              size = 17, face = "bold"),
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12)  
  )+ 
  scale_color_paletteer_d("vangogh::CafeTerrace")

```



# Evaluation Non-spiked Samples Only

Since all spiked samples produce negative values, we will continue our analyses using only non-spiked samples.

```{r message=FALSE}
# non-spiked samples only
data2 <-data[data$Spike == "No", ]

#two datasets, separated by dilution
data2.06 <- data2[data2$Buffer == "60 uL", ]
data2.25 <- data2[data2$Buffer == "250 uL", ]

#### fit models ####

# model Buffer = 0.06
model06 <- lm(Final_conc_pg.mg ~ Weight_mg, 
              data = data2.06)
r_squared06 <- summary(model06)$r.squared

# model Buffer = 0.25
model25 <- lm(Final_conc_pg.mg ~ Weight_mg, 
              data = data2.25)
r_squared25 <- summary(model25)$r.squared

# Calculate residuals
residuals06 <- residuals(model06)
residuals25 <- residuals(model25)

# Quantify residuals
# Mean Absolute Error
mae06 <- mean(abs(residuals06))          
# Standard Deviation of Residuals
std_dev06 <- sd(residuals06)   

# Mean Absolute Error
mae25 <- mean(abs(residuals25))      
# Standard Deviation of Residuals
std_dev25 <- sd(residuals25)                      



# scatterplot

ggplot(data2, aes(y = Final_conc_pg.mg, 
                  x = Weight_mg, 
                  color = Buffer, 
                  fill = Buffer)) +
  geom_point(size = 2.5) +  
  geom_text(label = c(data2$Sample), nudge_y = 0.75, nudge_x = -0.5) +
  geom_smooth(method = "lm", 
              color = "gold3", 
              se = TRUE,
              alpha = 0.1) + 
  geom_hline(yintercept = mean(data2$Final_conc_pg.mg), 
             color = "gray80",
             linetype = "dashed") +
  geom_hline(yintercept = mean(data2.06$Final_conc_pg.mg), 
             color = "lightblue3",
             linetype = "dashed") +
  geom_hline(yintercept = mean(data2.25$Final_conc_pg.mg), 
             color = "lightpink3",
             linetype = "dashed") +
  theme_minimal() +  
  xlim(5, max(data2$Weight_mg) + 4) +
  ylim(0, max(data2$Final_conc_pg.mg)+4) + 
  labs(
    title = "Final Cort Concentration and Weight
    (Non-spiked only)",
    y = "Final Concentration (pg/mg)",
    x = "Weight (mg)"  
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  
    axis.title = element_text(size = 14),  
    axis.text = element_text(size = 12) 
  ) +
  # Add R^2 annotation
  annotate("text", x = max(data2$Weight_mg) * 0.7, 
           y = min(data2$Final_conc_pg.mg) * 1.5,
           label = paste("R² =", round(r_squared06, 3)), 
           size = 5, color = "black") +
  annotate("text", x = max(data2$Weight_mg) * 0.7, 
           y = max(data2$Final_conc_pg.mg) * 0.84,
           label = paste("R² =", round(r_squared25, 3)), 
           size = 5, color = "black")

```

The previous figure shows that: 

- results are very stable across weights, particularly for the samples where a dilution of 250 uL was used 
- there is more error when using a dilution of 60 uL   
- dilution affects estimation of cortisol concentration in a significant way: even though final concentration numbers account for differences in the dilutions, the results we observe for each group do not overlap
- the average value when using 250 uL of buffer is twice as big as when using 60 uL


## Optimal dilution

**Error using 0.06 mL buffer**
```{r echo = FALSE}
# Print the results
cat("Mean Absolute Error (MAE) 0.06 mL:", round(mae06, 3), "\n")
cat("Standard Deviation of Residuals 0.06 mL:", round(std_dev06, 3), "\n")
```
**Error using 0.25 mL buffer**
```{r echo = FALSE}
cat("Mean Absolute Error (MAE) 0.25 mL:", round(mae25, 3), "\n") 
cat("Standard Deviation of Residuals 0.25 mL:", round(std_dev25, 3), "\n")

## Abs error and std dev. are larger for dilution 0.06 mL
```
From this we conclude that using **a 250 uL dilution provides more consistent results**

```{r echo = FALSE, include = FALSE}
# wflow_publish("./analysis/ELISA_Computation.Rmd")

```
